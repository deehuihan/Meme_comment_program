import pandas as pd
import numpy as np
from pathlib import Path
import json

INPUT  = "cleaned_data_1.xlsx"
OUTPUT = "summary.xlsx"

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 1. å°æ‡‰æ¬„ä½ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
col_map = {
    "user"   : "user_id",
    "age"    : "age",
    "gender" : "gender",
    "meme"   : "resp_meme_name",
    "post"   : "resp_post_id",
    "rt"     : "resp_response_time_ms",
    "emo"    : "resp_english_label",
    "status" : "status",
    "email_provided" : "email_provided",
    "attention_passed" : "attention_passed",
    "participation" : "participation",
    "game_duration" : "game_duration"
}

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 2. è®€æª” & åŸºæœ¬è½‰æ› â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
print("ğŸ“Š æ­£åœ¨è®€å–è³‡æ–™...")
df = pd.read_excel(INPUT)
df[col_map["rt"]] = pd.to_numeric(df[col_map["rt"]], errors="coerce") / 1000.0  # ms â†’ ç§’

print(f"âœ… è³‡æ–™è®€å–å®Œæˆï¼š{len(df)} ç­†è¨˜éŒ„ï¼Œ{df[col_map['user']].nunique()} ä½ä½¿ç”¨è€…")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 3. å»ºç«‹æƒ…ç·’æ¬¡æ•¸å‡½æ•¸ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def emotion_counts(group_key: str) -> pd.DataFrame:
    """å›å‚³ group_key Ã— emotion å››é¡æ¬¡æ•¸çš„ wide è¡¨"""
    emo_tbl = (
        df.groupby([group_key, col_map["emo"]])
          .size()
          .unstack(col_map["emo"], fill_value=0)
          .reset_index()
    )
    # é‡æ–°å‘½åæƒ…ç·’æ¬„ä½
    emo_cols = {}
    for col in emo_tbl.columns:
        if col in ["anger", "contempt", "disgust", "others"]:
            emo_cols[col] = f"cnt_{col}"
    emo_tbl = emo_tbl.rename(columns=emo_cols)
    return emo_tbl

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 4. ä½¿ç”¨è€…å±¤ç´šçš„è©³ç´°åˆ†æ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def user_detailed_analysis():
    """ä½¿ç”¨è€…å±¤ç´šçš„è©³ç´°çµ±è¨ˆ"""
    user_stats = df.groupby(col_map["user"]).agg({
        col_map["age"]: "first",
        col_map["gender"]: "first", 
        col_map["status"]: "first",
        col_map["email_provided"]: "first",
        col_map["participation"]: "first",
        col_map["game_duration"]: "first",
        col_map["rt"]: ["count", "mean", "median", "std", "min", "max"],
        col_map["emo"]: lambda x: x.value_counts().to_dict()
    }).reset_index()
    
    # å¹³æ•´åŒ–å¤šå±¤ç´šæ¬„ä½åç¨±
    user_stats.columns = [
        col_map["user"], "age", "gender", "status", "email_provided", 
        "participation", "game_duration_sec",
        "total_responses", "avg_response_time", "median_response_time", 
        "std_response_time", "min_response_time", "max_response_time",
        "emotion_breakdown"
    ]
    
    # å±•é–‹æƒ…ç·’çµ±è¨ˆ
    emotion_df = pd.json_normalize(user_stats['emotion_breakdown'])
    emotion_df = emotion_df.fillna(0).astype(int)
    emotion_df.columns = [f"cnt_{col}" for col in emotion_df.columns]
    
    user_stats = pd.concat([user_stats.drop('emotion_breakdown', axis=1), emotion_df], axis=1)
    
    return user_stats

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 5. å¹´é½¡Ã—æ€§åˆ¥çš„è©³ç´°äº¤å‰åˆ†æ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def age_gender_detailed():
    """å¹´é½¡Ã—æ€§åˆ¥çš„è©³ç´°äº¤å‰åˆ†æ"""
    # åŸºæœ¬äººæ•¸çµ±è¨ˆ
    demo_crosstab = pd.crosstab(
        df[col_map["age"]], 
        df[col_map["gender"]], 
        aggfunc='nunique', 
        values=df[col_map["user"]]
    ).fillna(0).reset_index()
    
    # å¹³å‡åæ‡‰æ™‚é–“
    rt_crosstab = df.groupby([col_map["age"], col_map["gender"]])[col_map["rt"]].mean().unstack(fill_value=0).reset_index()
    rt_crosstab.columns = [col_map["age"]] + [f"avg_rt_{col}" for col in rt_crosstab.columns[1:]]
    
    # å¹³å‡éŠæˆ²æ™‚é•·
    duration_crosstab = df.groupby([col_map["age"], col_map["gender"]])[col_map["game_duration"]].mean().unstack(fill_value=0).reset_index()
    duration_crosstab.columns = [col_map["age"]] + [f"avg_game_duration_{col}" for col in duration_crosstab.columns[1:]]
    
    # åˆä½µæ‰€æœ‰çµ±è¨ˆ
    age_gender_summary = demo_crosstab.merge(rt_crosstab, on=col_map["age"]).merge(duration_crosstab, on=col_map["age"])
    
    return age_gender_summary

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 6. æƒ…ç·’åˆ†ä½ˆçš„è©³ç´°åˆ†æ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def emotion_detailed_analysis():
    """å„ç¾¤é«”çš„æƒ…ç·’åˆ†ä½ˆè©³ç´°åˆ†æ"""
    
    # å¹´é½¡å±¤çš„æƒ…ç·’åˆ†ä½ˆ
    age_emotion = df.groupby([col_map["age"], col_map["emo"]]).size().unstack(fill_value=0)
    age_emotion_pct = age_emotion.div(age_emotion.sum(axis=1), axis=0).round(3)
    age_emotion_pct.columns = [f"pct_{col}" for col in age_emotion_pct.columns]
    age_emotion_combined = pd.concat([age_emotion, age_emotion_pct], axis=1).reset_index()
    
    # æ€§åˆ¥çš„æƒ…ç·’åˆ†ä½ˆ
    gender_emotion = df.groupby([col_map["gender"], col_map["emo"]]).size().unstack(fill_value=0)
    gender_emotion_pct = gender_emotion.div(gender_emotion.sum(axis=1), axis=0).round(3)
    gender_emotion_pct.columns = [f"pct_{col}" for col in gender_emotion_pct.columns]
    gender_emotion_combined = pd.concat([gender_emotion, gender_emotion_pct], axis=1).reset_index()
    
    return age_emotion_combined, gender_emotion_combined

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 7. åæ‡‰æ™‚é–“åˆ†æ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def response_time_analysis():
    """åæ‡‰æ™‚é–“çš„è©³ç´°åˆ†æ"""
    
    # å„å¹´é½¡å±¤çš„åæ‡‰æ™‚é–“çµ±è¨ˆ
    age_rt_stats = df.groupby(col_map["age"])[col_map["rt"]].agg([
        'count', 'mean', 'median', 'std', 'min', 'max',
        lambda x: x.quantile(0.25),
        lambda x: x.quantile(0.75)
    ]).round(3).reset_index()
    age_rt_stats.columns = [col_map["age"], 'count', 'mean_rt', 'median_rt', 'std_rt', 
                           'min_rt', 'max_rt', 'q25_rt', 'q75_rt']
    
    # å„æ€§åˆ¥çš„åæ‡‰æ™‚é–“çµ±è¨ˆ
    gender_rt_stats = df.groupby(col_map["gender"])[col_map["rt"]].agg([
        'count', 'mean', 'median', 'std', 'min', 'max',
        lambda x: x.quantile(0.25),
        lambda x: x.quantile(0.75)
    ]).round(3).reset_index()
    gender_rt_stats.columns = [col_map["gender"], 'count', 'mean_rt', 'median_rt', 'std_rt',
                              'min_rt', 'max_rt', 'q25_rt', 'q75_rt']
    
    # å„æƒ…ç·’çš„åæ‡‰æ™‚é–“çµ±è¨ˆ
    emotion_rt_stats = df.groupby(col_map["emo"])[col_map["rt"]].agg([
        'count', 'mean', 'median', 'std', 'min', 'max'
    ]).round(3).reset_index()
    emotion_rt_stats.columns = [col_map["emo"], 'count', 'mean_rt', 'median_rt', 'std_rt',
                               'min_rt', 'max_rt']
    
    return age_rt_stats, gender_rt_stats, emotion_rt_stats

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 8. Meme è¡¨ç¾åˆ†æ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def meme_performance_analysis():
    """å„ Meme çš„è©³ç´°è¡¨ç¾åˆ†æ"""
    
    meme_stats = df.groupby(col_map["meme"]).agg({
        col_map["user"]: "nunique",
        col_map["rt"]: ["count", "mean", "median", "std"],
        col_map["emo"]: lambda x: x.value_counts().to_dict()
    }).reset_index()
    
    # å¹³æ•´åŒ–æ¬„ä½åç¨±
    meme_stats.columns = [col_map["meme"], "unique_users", "total_responses", 
                         "avg_rt", "median_rt", "std_rt", "emotion_breakdown"]
    
    # å±•é–‹æƒ…ç·’åˆ†ä½ˆ
    emotion_df = pd.json_normalize(meme_stats['emotion_breakdown'])
    emotion_df = emotion_df.fillna(0).astype(int)
    emotion_df.columns = [f"cnt_{col}" for col in emotion_df.columns]
    
    meme_detailed = pd.concat([meme_stats.drop('emotion_breakdown', axis=1), emotion_df], axis=1)
    
    # è¨ˆç®—æƒ…ç·’æ¯”ä¾‹
    emotion_cols = [col for col in emotion_df.columns]
    total_responses = meme_detailed['total_responses']
    for col in emotion_cols:
        pct_col = col.replace('cnt_', 'pct_')
        meme_detailed[pct_col] = (meme_detailed[col] / total_responses).round(3)
    
    return meme_detailed

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 9. å®Œæˆåº¦åˆ†æ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def completion_analysis():
    """ä½¿ç”¨è€…å®Œæˆåº¦å’Œåƒèˆ‡åº¦åˆ†æ"""
    
    completion_stats = df.groupby([col_map["status"], col_map["email_provided"], col_map["participation"]]).agg({
        col_map["user"]: "nunique",
        col_map["game_duration"]: ["mean", "median", "std"]
    }).reset_index()
    
    completion_stats.columns = ["status", "email_provided", "participation", 
                               "user_count", "avg_game_duration", "median_game_duration", "std_game_duration"]
    
    return completion_stats

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 10. åŸ·è¡Œæ‰€æœ‰åˆ†æä¸¦è¼¸å‡º â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
print("ğŸ”„ é–‹å§‹åŸ·è¡Œè©³ç´°åˆ†æ...")

# åŸå§‹çš„åŸºæœ¬åˆ†æï¼ˆä¿ç•™ï¼‰
def build_demo_summary(group_key: str) -> pd.DataFrame:
    basic = (
        df.groupby(group_key)
          .agg(users        = (col_map["user"], "nunique"),
               avg_resp_sec = (col_map["rt"],   "mean"))
          .reset_index()
    )
    age_gender = (
        df.groupby([group_key, col_map["age"], col_map["gender"]])
          .size()
          .unstack([col_map["age"], col_map["gender"]], fill_value=0)
          .reset_index()
    )
    return basic.merge(age_gender, on=group_key)

# åŸ·è¡Œå„ç¨®åˆ†æ
print("ğŸ“ˆ åˆ†æä½¿ç”¨è€…è©³ç´°è³‡æ–™...")
user_detailed = user_detailed_analysis()

print("ğŸ“Š åˆ†æå¹´é½¡æ€§åˆ¥äº¤å‰çµ±è¨ˆ...")
age_gender_detailed = age_gender_detailed()

print("ğŸ˜Š åˆ†ææƒ…ç·’åˆ†ä½ˆ...")
age_emotion, gender_emotion = emotion_detailed_analysis()

print("â±ï¸ åˆ†æåæ‡‰æ™‚é–“...")
age_rt, gender_rt, emotion_rt = response_time_analysis()

print("ğŸ­ åˆ†æ Meme è¡¨ç¾...")
meme_detailed = meme_performance_analysis()

print("âœ… åˆ†æå®Œæˆåº¦...")
completion_stats = completion_analysis()

# åŸå§‹åˆ†æï¼ˆä¿æŒç›¸å®¹æ€§ï¼‰
meme_demo = build_demo_summary(col_map["meme"])
meme_emo = emotion_counts(col_map["meme"])
meme_sum = meme_demo.merge(meme_emo, on=col_map["meme"])

post_demo = build_demo_summary(col_map["post"])
post_emo = emotion_counts(col_map["post"])
post_sum = post_demo.merge(post_emo, on=col_map["post"])

age_break = (df.groupby([col_map["age"], col_map["meme"]])
               .size().unstack(col_map["meme"], fill_value=0).reset_index())
gender_break = (df.groupby([col_map["gender"], col_map["meme"]])
                  .size().unstack(col_map["meme"], fill_value=0).reset_index())

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 11. è¼¸å‡ºåˆ° Excel â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
print("ğŸ’¾ æ­£åœ¨è¼¸å‡ºçµæœ...")

with pd.ExcelWriter(OUTPUT, engine="xlsxwriter") as w:
    # === åŸå§‹è¡¨æ ¼ï¼ˆå‘å¾Œç›¸å®¹ï¼‰ ===
    meme_sum.to_excel(w, index=False, sheet_name="meme_summary")
    post_sum.to_excel(w, index=False, sheet_name="post_summary")
    age_break.to_excel(w, index=False, sheet_name="age_breakdown")
    gender_break.to_excel(w, index=False, sheet_name="gender_breakdown")
    
    # === æ–°å¢çš„è©³ç´°åˆ†æè¡¨æ ¼ ===
    # ä½¿ç”¨è€…è©³ç´°åˆ†æ
    user_detailed.to_excel(w, index=False, sheet_name="user_detailed_stats")
    
    # äººå£çµ±è¨ˆè©³ç´°äº¤å‰åˆ†æ
    age_gender_detailed.to_excel(w, index=False, sheet_name="age_gender_detailed")
    
    # æƒ…ç·’åˆ†ä½ˆåˆ†æ
    age_emotion.to_excel(w, index=False, sheet_name="age_emotion_distribution")
    gender_emotion.to_excel(w, index=False, sheet_name="gender_emotion_distribution")
    
    # åæ‡‰æ™‚é–“åˆ†æ
    age_rt.to_excel(w, index=False, sheet_name="age_response_time")
    gender_rt.to_excel(w, index=False, sheet_name="gender_response_time")
    emotion_rt.to_excel(w, index=False, sheet_name="emotion_response_time")
    
    # Meme è©³ç´°è¡¨ç¾åˆ†æ
    meme_detailed.to_excel(w, index=False, sheet_name="meme_detailed_performance")
    
    # å®Œæˆåº¦åˆ†æ
    completion_stats.to_excel(w, index=False, sheet_name="completion_analysis")
    
    # === é¡å¤–çš„æ·±åº¦åˆ†æ ===
    # å¹´é½¡å±¤å…§çš„æ€§åˆ¥åˆ†ä½ˆç´°ç¯€
    age_gender_count = pd.crosstab(
        df[col_map["age"]], 
        df[col_map["gender"]], 
        values=df[col_map["user"]], 
        aggfunc='nunique'
    ).fillna(0).reset_index()
    age_gender_count.to_excel(w, index=False, sheet_name="age_gender_user_count")
    
    # æ¯å€‹ä½¿ç”¨è€…çš„æƒ…ç·’æ¨™è¨»ç¸½çµ
    user_emotion_summary = df.groupby(col_map["user"])[col_map["emo"]].value_counts().unstack(fill_value=0).reset_index()
    user_emotion_summary.to_excel(w, index=False, sheet_name="user_emotion_summary")
    
    # åæ‡‰æ™‚é–“å€é–“åˆ†æ
    df['rt_bin'] = pd.cut(df[col_map["rt"]], bins=[0, 1, 2, 5, 10, float('inf')], 
                         labels=['<1s', '1-2s', '2-5s', '5-10s', '>10s'])
    rt_bin_analysis = pd.crosstab(df['rt_bin'], df[col_map["emo"]]).reset_index()
    rt_bin_analysis.to_excel(w, index=False, sheet_name="response_time_bins")

print(f"âœ… å®Œæˆï¼å·²è¼¸å‡ºè©³ç´°åˆ†æåˆ° {Path(OUTPUT).resolve()}")
print(f"ğŸ“‹ ç¸½å…±åŒ…å« {len(pd.ExcelFile(OUTPUT).sheet_names)} å€‹å·¥ä½œè¡¨ï¼š")

# åˆ—å‡ºæ‰€æœ‰å·¥ä½œè¡¨
sheet_descriptions = {
    "meme_summary": "Meme åŸºæœ¬çµ±è¨ˆï¼ˆåŸå§‹ï¼‰",
    "post_summary": "Post åŸºæœ¬çµ±è¨ˆï¼ˆåŸå§‹ï¼‰", 
    "age_breakdown": "å¹´é½¡åˆ†ä½ˆï¼ˆåŸå§‹ï¼‰",
    "gender_breakdown": "æ€§åˆ¥åˆ†ä½ˆï¼ˆåŸå§‹ï¼‰",
    "user_detailed_stats": "ä½¿ç”¨è€…è©³ç´°çµ±è¨ˆï¼ˆæ–°ï¼‰",
    "age_gender_detailed": "å¹´é½¡Ã—æ€§åˆ¥è©³ç´°äº¤å‰åˆ†æï¼ˆæ–°ï¼‰",
    "age_emotion_distribution": "å¹´é½¡å±¤æƒ…ç·’åˆ†ä½ˆï¼ˆæ–°ï¼‰",
    "gender_emotion_distribution": "æ€§åˆ¥æƒ…ç·’åˆ†ä½ˆï¼ˆæ–°ï¼‰",
    "age_response_time": "å¹´é½¡å±¤åæ‡‰æ™‚é–“çµ±è¨ˆï¼ˆæ–°ï¼‰",
    "gender_response_time": "æ€§åˆ¥åæ‡‰æ™‚é–“çµ±è¨ˆï¼ˆæ–°ï¼‰",
    "emotion_response_time": "å„æƒ…ç·’åæ‡‰æ™‚é–“çµ±è¨ˆï¼ˆæ–°ï¼‰",
    "meme_detailed_performance": "Meme è©³ç´°è¡¨ç¾åˆ†æï¼ˆæ–°ï¼‰",
    "completion_analysis": "å®Œæˆåº¦å’Œåƒèˆ‡åº¦åˆ†æï¼ˆæ–°ï¼‰",
    "age_gender_user_count": "å¹´é½¡Ã—æ€§åˆ¥ä½¿ç”¨è€…äººæ•¸çµ±è¨ˆï¼ˆæ–°ï¼‰",
    "user_emotion_summary": "æ¯ä½ä½¿ç”¨è€…æƒ…ç·’æ¨™è¨»çµ±è¨ˆï¼ˆæ–°ï¼‰",
    "response_time_bins": "åæ‡‰æ™‚é–“å€é–“åˆ†æï¼ˆæ–°ï¼‰"
}

for sheet, desc in sheet_descriptions.items():
    print(f"  ğŸ“„ {sheet}: {desc}")

print("\nğŸ‰ æ‰€æœ‰åˆ†æå®Œæˆï¼")