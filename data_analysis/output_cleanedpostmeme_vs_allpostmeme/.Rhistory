R.version.string
source("C:/Users/deehu/Desktop/Program/data_analysis/cleanedpostmeme_vs_allpostmeme.R", echo = TRUE)
install.packages(c("readxl", "dplyr", "ggplot2", "tidyr", "gridExtra", "corrplot"))
install.packages(c("readxl", "dplyr", "ggplot2", "tidyr", "gridExtra", "corrplot"))
install.packages(c("readxl", "dplyr", "ggplot2", "tidyr", "gridExtra", "corrplot"))
source("C:/Users/deehu/Desktop/Program/data_analysis/cleanedpostmeme_vs_allpostmeme.R", echo = TRUE)
source("C:/Users/deehu/Desktop/Program/data_analysis/cleanedpostmeme_vs_allpostmeme.R", echo = TRUE)
source("C:/Users/deehu/Desktop/Program/data_analysis/cleanedpostmeme_vs_allpostmeme.R", echo = TRUE)
source("C:/Users/deehu/Desktop/Program/data_analysis/cleanedpostmeme_vs_allpostmeme.R", echo = TRUE)
source("C:/Users/deehu/Desktop/Program/data_analysis/cleanedpostmeme_vs_allpostmeme.R", echo = TRUE)
source("C:/Users/deehu/Desktop/Program/data_analysis/cleanedpostmeme_vs_allpostmeme.R", echo = TRUE)
library(readxl)
library(dplyr)
# 測試檔案是否存在
file.exists("C:/Users/deehu/Desktop/Program/data_analysis/cleaned_data_1.xlsx")
# 測試讀取
data <- read_excel("C:/Users/deehu/Desktop/Program/data_analysis/cleaned_data_1.xlsx", sheet = "Cleaned_Data")
cat("原始數據筆數:", nrow(data), "\n")
library(ggplot2)
library(tidyr)
# 設定乾淨的 post IDs
clean_post_ids <- c(8, 13, 20, 25, 27, 44)
# 過濾有效數據
valid_data <- data %>%
filter(!is.na(resp_english_label),
resp_english_label != "others",
!grepl("attention_check", resp_image_path, fixed = TRUE))
cat("過濾後有效數據筆數:", nrow(valid_data), "\n")
# 分離乾淨 post 數據
clean_post_data <- valid_data %>%
filter(resp_post_id %in% clean_post_ids)
cat("乾淨 post 數據筆數:", nrow(clean_post_data), "\n")
# Meme 情緒分布比較分析
# 比較乾淨 post 與所有 post 下的 meme 情緒分布
# 載入必要的套件
library(readxl)
library(dplyr)
library(ggplot2)
library(tidyr)
library(gridExtra)
library(corrplot)
# 設定乾淨的 post IDs
clean_post_ids <- c(8, 13, 20, 25, 27, 44)
# ================================
# 1. 讀取和準備數據
# ================================
# 讀取數據 (請修改路徑)
data <- read_excel("cleaned_data_1.xlsx", sheet = "Cleaned_Data")
很好！現在繼續執行步驟 2：
# 計算 meme 情緒分布的函數
calculate_meme_distribution <- function(data_subset) {
meme_dist <- data_subset %>%
filter(resp_english_label %in% c("contempt", "anger", "disgust")) %>%
group_by(resp_meme_name, resp_english_label) %>%
summarise(count = n(), .groups = "drop") %>%
group_by(resp_meme_name) %>%
mutate(total = sum(count),
percentage = count / total) %>%
select(resp_meme_name, resp_english_label, percentage, total) %>%
pivot_wider(names_from = resp_english_label,
values_from = percentage,
values_fill = 0) %>%
# 確保所有三種情緒都存在
mutate(contempt = ifelse(is.na(contempt), 0, contempt),
anger = ifelse(is.na(anger), 0, anger),
disgust = ifelse(is.na(disgust), 0, disgust))
return(meme_dist)
}
# 計算兩種分布
clean_distribution <- calculate_meme_distribution(clean_post_data)
cat("乾淨 post 下的 meme 數量:", nrow(clean_distribution), "\n")
all_distribution <- calculate_meme_distribution(valid_data)
cat("所有 post 下的 meme 數量:", nrow(all_distribution), "\n")
# 合併數據並計算相似度
comparison_data <- inner_join(clean_distribution, all_distribution,
by = "resp_meme_name",
suffix = c("_clean", "_all"))
cat("共同 meme 數量:", nrow(comparison_data), "\n")
# 計算 Cosine Similarity 的函數
calculate_cosine_similarity <- function(vec1, vec2) {
dot_product <- sum(vec1 * vec2)
norm1 <- sqrt(sum(vec1^2))
norm2 <- sqrt(sum(vec2^2))
if (norm1 == 0 || norm2 == 0) return(0)
return(dot_product / (norm1 * norm2))
}
# 計算每個 meme 的 cosine similarity
comparison_data$cosine_similarity <- apply(comparison_data, 1, function(row) {
clean_vec <- c(as.numeric(row["contempt_clean"]),
as.numeric(row["anger_clean"]),
as.numeric(row["disgust_clean"]))
all_vec <- c(as.numeric(row["contempt_all"]),
as.numeric(row["anger_all"]),
as.numeric(row["disgust_all"]))
calculate_cosine_similarity(clean_vec, all_vec)
})
cat("\n=== 分析結果摘要 ===\n")
cat("共同 meme 數量:", nrow(comparison_data), "\n")
cat("平均 Cosine Similarity:", round(mean(comparison_data$cosine_similarity), 3), "\n")
cat("Cosine Similarity 標準差:", round(sd(comparison_data$cosine_similarity), 3), "\n")
cat("最小 Cosine Similarity:", round(min(comparison_data$cosine_similarity), 3), "\n")
cat("最大 Cosine Similarity:", round(max(comparison_data$cosine_similarity), 3), "\n")
# 相似度分類
high_similarity <- sum(comparison_data$cosine_similarity > 0.8)
medium_similarity <- sum(comparison_data$cosine_similarity > 0.6 & comparison_data$cosine_similarity <= 0.8)
low_similarity <- sum(comparison_data$cosine_similarity <= 0.6)
cat("\n=== 相似度分類 ===\n")
cat("高相似度 (>0.8):", high_similarity, "個 memes (", round(high_similarity/nrow(comparison_data)*100, 1), "%)\n")
cat("中等相似度 (0.6-0.8):", medium_similarity, "個 memes (", round(medium_similarity/nrow(comparison_data)*100, 1), "%)\n")
cat("低相似度 (<=0.6):", low_similarity, "個 memes (", round(low_similarity/nrow(comparison_data)*100, 1), "%)\n")
# 1. 儲存完整的比較分析結果
detailed_comparison <- comparison_data %>%
arrange(desc(cosine_similarity)) %>%
mutate(
similarity_category = case_when(
cosine_similarity > 0.8 ~ "High",
cosine_similarity > 0.6 ~ "Medium",
TRUE ~ "Low"
)
) %>%
select(resp_meme_name,
contempt_clean, anger_clean, disgust_clean, total_clean,
contempt_all, anger_all, disgust_all, total_all,
cosine_similarity, similarity_category)
# 儲存詳細比較結果
write.csv(detailed_comparison, "meme_similarity_comparison.csv", row.names = FALSE)
# 2. 儲存推薦系統用的 meme 情緒資料庫
meme_emotion_database <- all_distribution %>%
select(resp_meme_name, contempt, anger, disgust, total) %>%
rename(meme_name = resp_meme_name)
write.csv(meme_emotion_database, "meme_emotion_database.csv", row.names = FALSE)
# 3. 儲存高穩定性 memes（相似度 > 0.8）
high_stability_memes <- comparison_data %>%
filter(cosine_similarity > 0.8) %>%
select(resp_meme_name, contempt_all, anger_all, disgust_all, total_all, cosine_similarity) %>%
rename(meme_name = resp_meme_name,
contempt = contempt_all,
anger = anger_all,
disgust = disgust_all,
total = total_all) %>%
arrange(desc(cosine_similarity))
write.csv(high_stability_memes, "high_stability_memes.csv", row.names = FALSE)
# 4. 查看檔案是否成功生成
cat("檔案已生成在工作目錄:", getwd(), "\n")
cat("生成的檔案:\n")
cat("- meme_similarity_comparison.csv (完整比較分析)\n")
cat("- meme_emotion_database.csv (所有 memes 情緒分布)\n")
cat("- high_stability_memes.csv (高穩定性 memes)\n")
# 5. 預覽資料
cat("\n=== 推薦系統資料庫預覽 ===\n")
print(head(meme_emotion_database, 10))
cat("\n=== 高穩定性 Memes 預覽 ===\n")
print(head(high_stability_memes, 10))
list.files()
source("C:/Users/deehu/Desktop/Program/data_analysis/cleanedpostmeme_vs_allpostmeme.R", echo = TRUE)
list.files()
setwd("C:/Users/deehu/Desktop/Program/data_analysis")
getwd()
list.files()
source("C:/Users/deehu/Desktop/Program/data_analysis/cleanedpostmeme_vs_allpostmeme.R", echo = TRUE)
source("C:/Users/deehu/Desktop/Program/data_analysis/cleanedpostmeme_vs_allpostmeme.R", echo = TRUE)
source("C:/Users/deehu/Desktop/Program/data_analysis/cleanedpostmeme_vs_allpostmeme.R", echo = TRUE)
source("C:/Users/deehu/Desktop/Program/data_analysis/cleanedpostmeme_vs_allpostmeme.R", echo = TRUE)
source("C:/Users/deehu/Desktop/Program/data_analysis/cleanedpostmeme_vs_allpostmeme.R", echo = TRUE)
source("C:/Users/deehu/Desktop/Program/data_analysis/chi_square_post.R", encoding = 'CP936', echo = TRUE)
source("C:/Users/deehu/Desktop/Program/data_analysis/chi_square_post.R", encoding = 'CP936', echo = TRUE)
source("C:/Users/deehu/Desktop/Program/data_analysis/chi_square_post.R", encoding = 'CP936', echo = TRUE)
source("C:/Users/deehu/Desktop/Program/data_analysis/cleanedpostmeme_vs_allpostmeme.R", echo = TRUE)
source("C:/Users/deehu/Desktop/Program/data_analysis/cleanedpostmeme_vs_allpostmeme.R", echo = TRUE)
source("C:/Users/deehu/Desktop/Program/data_analysis/chi_square_meme.R", echo = TRUE)
source("C:/Users/deehu/Desktop/Program/data_analysis/chi_square_post.R", encoding = 'CP936', echo = TRUE)
source("C:/Users/deehu/Desktop/Program/data_analysis/cleanedpostmeme_vs_allpostmeme.R", echo = TRUE)
